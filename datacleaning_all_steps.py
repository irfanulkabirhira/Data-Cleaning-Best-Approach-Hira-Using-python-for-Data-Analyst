# -*- coding: utf-8 -*-
"""DataCleaning All Steps.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1FZMsKQbawczfb10mVqbh4CuWJQKukPUT

# 1st Dataset [ Load ]

# 💡Importing pandas for Handling the Missing value
"""

import pandas as pd
dataset= pd.read_csv(r'C:\Users\hirak\Downloads\Data Cleaning For Data Analyst\loan.csv')
dataset.head(2)

dataset.shape

"""# ✅Step 1 : Removing Null values

### 📍Check Null value exist or not
"""

dataset.isnull().sum()

"""### 📍Total presnt of Null Value"""

dataset.isnull().sum().sum()

"""### 📍Show Null value as percentage"""

dataset.isnull().sum()/dataset.shape[0]*100

"""### 📍Show Total Null value as percentage"""

(dataset.isnull().sum().sum()/(dataset.shape[0]*dataset.shape[1]))*100

"""### 📍Koto gula Not Null Value ache"""

dataset.notnull().sum().sum()

"""## To show the graphical representation of Null value"""

import seaborn as sns
import matplotlib.pyplot as plt

sns.heatmap(dataset.isnull())
plt.show()

"""### 📍Null value removing --> Removing those Rows"""

dataset.dropna(inplace=True)

dataset.isnull().sum()

dataset.shape

"""# ✅Step 2 : Remiving Duplicate Rows

### 📍check Duplicate value
"""

dataset.duplicated().sum()

"""### 📍If Duplicte Values were existed , then removing procedure

"""

dataset.drop_duplicates(inplace=True)

"""# ✅Step3 : Changing the Datatype if needed"""

dataset.dtypes

"""### 📍Convert LoanAmount to integer

"""

dataset['LoanAmount'] = dataset['LoanAmount'].astype(int)

dataset.dtypes

dataset.head(1)

"""# ✅Step 4 : Removing Column"""

dataset.drop(columns = ['Credit_History'],inplace=True)

dataset.head(2)

"""# ✅Step 5 : Renaming Column"""

dataset.rename(columns={'Property_Area' : 'Area'}, inplace=True)

dataset.columns

dataset.head(1)

"""# ✅Step 6 : Merging Columns (if needed)"""

dataset['Gender_self_employment'] = dataset['Gender']+ '_'+ dataset['Self_Employed']

dataset.head(1)

"""# ✅Step 7 : Splitting columns (if needed)

## 🍅in this dataset it's not needed🍅

# ✅Step 8 : Sorting Column ( if needed)

### 📍 Sort by LoanAmount in ascending order
"""

dataset.sort_values(by='LoanAmount', inplace=True)

"""### 📍Sort by LoanAmount in descending order

"""

dataset.sort_values(by='LoanAmount', ascending=False, inplace=True)

"""# ✅9th step: Filtering my dataset (if needed)

###  📍Example 1: Filter where LoanAmount < 200
"""

Filter = dataset[dataset['LoanAmount'] < 200]
Filter.head(2)

"""### 📍Example 2: Filter where Gender is 'Male'"""

Filter = dataset[dataset['Gender']== 'Male']
Filter.head(2)

"""### 📍Example 3: Filter where Area is 'Urban' and LoanAmount > 150"""

Filter = dataset[(dataset['Area']== 'Urban') & (dataset['LoanAmount'] > 150)]
Filter.head(2)

"""# ✅Finaly import the Cleaned Data"""

dataset.to_csv(r'C:\Users\hirak\Downloads\Data Cleaning For Data Analyst\Cleaned_Load_Data.csv')

"""# 2nd Dataset Cleaning [ Car price Dataset ]

# 💡Importing pandas for Handling the Missing value
"""

import pandas as plt
data = pd.read_csv("Car_Price_MyOwn_Data.csv")
data.head(2)

data.shape

"""### To See the DataType"""

data.info()

"""# ✅Step 1 : Removing Null values

### 📍Check Null value exist or not
"""

data.isnull().sum()

"""### 📍Total presnt of Null Value"""

data.isnull().sum().sum()

"""### 📍Show Null value as percentage"""

data.isnull().sum()/data.shape[0]*100

"""### 📍Show Total Null value as percentage"""

(data.isnull().sum().sum()/(data.shape[0]*data.shape[1]))*100

"""### 📍Koto gula Not Null Value ache"""

data.notnull().sum().sum()

"""## To show the graphical representation of Null value"""

import seaborn as sns
import matplotlib.pyplot as plt

sns.heatmap(data.isnull())
plt.show()

"""### 📍Null value removing --> Removing those Rows"""

data.dropna(inplace=True)

data.isnull().sum()

data.shape

"""# ✅Step 2: Removing Duplicate Values

### 📍Check Duplicate Values
"""

data.duplicated().sum()

"""### 📍If Duplicte Values"""

data.drop_duplicates(inplace=True)

"""# ✅Step 3 : Changing the Datatype if needed"""

data.dtypes

data.head(1)

"""# 📌One By One Cloumn Obeservation

# 📍Car_name
"""

data['car_name']

"""### 👉What we will do is , split the "Car_name" into Car_name and company_name"""

# WE Will work on a Data only,Then entire Data
data['car_name'][0]

# I will use Slicing to separate the Car name and Company Name
x=data['car_name'][0]
x[:x.index(" ")] # For Specific Data, so entire Data, I will have to create the customized function

# To Create the customize function --> for the company_name
def company_name(x):
    return x[:x.index(" ")]

data["car_name"].apply(company_name)

# TO add this in the Main Dataset we will do is .......
data["company_name"]=data["car_name"].apply(company_name)

data.head(1)

# To Create the customize function --> for the car_name
def car_name(x):
    return x[x.index(" ")+1:]

data["car_name"].apply(car_name)

# To add this in the Main Dataset we will do is .......
data["car_name"]=data["car_name"].apply(car_name)

data.head(1)

"""# 📍Car_price_in_Rupes"""

data["car_prices_in_rupee"]

# Remove the coma first ---> using [str] and [replace]   ==> like 35,000----to --> 3500
data["car_prices_in_rupee"] = data["car_prices_in_rupee"].str.replace(",","")

data

# 16.40 crore ----To ----> 16.40* 100000000
16.40* 100000000

# ["16.40", "Crore"] ekhane 0 index = 16.40-->p[0]   And Crore hocce = 1 index -->p[1]
# ["10.03", "Lakh"] ekhane 0 index = 10.03-->p[0]  And Lakh hocce = 1 index -->p[1]

# The steps that i am going to do is--> Step: 1
l= "10.03 Lakh"
a = l.split(" ")
a # Now I will find the Data in the list

# Working with 28.90 or index = zero --> step: 2
l= "10.03 Lakh"
a = l.split(" ")
a[0]

# Now I Will Multiply this value 28.9 by 100000 ----> so that I find the Number in thousands --> step: 4
l= "10.03 Lakh"
a = l.split(" ")
float(a[0])*100000

# If any round value, to reduce that mistake, we will use the Round function -----> step: 5
# Such that round(3.14159, 2) rounds the number to two decimal places, resulting in 3.14.
l= "10.03 Lakh"
a = l.split(" ")
round(float(a[0])*100000,1)

# To Create this Function And -> pura process jeta hocce sheta String Format e convert kore again insert korteci

#try and except: Handles unexpected errors (like missing or malformed input) and prevents your program from crashing.
#else: Provides an alternative path if none of the if or elif conditions are met, but it does not handle errors.


def rupe_change(x):
    p = x.split(" ")
    try:
        if p[1] == "Lakh":
            return str(round(float(p[0]) * 100000, 1))
        elif p[1] == "Crore":
            return str(round(float(p[0]) * 10000000, 1))
    except:
        return x

data["car_prices_in_rupee"].apply(rupe_change)

# To check the conversion type
data["car_prices_in_rupee"] =data["car_prices_in_rupee"].apply(rupe_change)

data.info()

# In the above section I see, the car_price_in_rupee is still in Object Form
# So let's Convert this into float Value

data["car_prices_in_rupee"].astype("float") # Now it is converted into floating Value

#Now loading this into the Dataset
data["car_prices_in_rupee"]=data["car_prices_in_rupee"].astype("float64") # Now it is converted into floating Value

data.head()

"""# 📌Kms_driveen"""

data['kms_driven']

# Remove the coma first ---> using [str] and [replace]   ==> like 35,000----to --> 3500
data["kms_driven"] = data["kms_driven"].str.replace(",","")

data['kms_driven']

# To Create this Function And -> pura process jeta hocce sheta String Format e convert kore again insert korteci

#try and except: Handles unexpected errors (like missing or malformed input) and prevents your program from crashing.
#else: Provides an alternative path if none of the if or elif conditions are met, but it does not handle errors.


def kms_remove(y):
    h = y.split(" ")
    try:
        if h[1] == "kms":
            return str(round(float(h[0]), 1))
    except:
        return y

data["kms_driven"].apply(kms_remove)

data.info()

# In the above section I see, the kms_driven is still in Object Form
# So let's convert this into a float Value

data["kms_driven"].astype("float") # Now it is converted into floating Value

## Showing another Kms ---> removing that too
data['kms_driven'] = data['kms_driven'].str.replace(" kms", "")

# Now converitng to this as int value
data["kms_driven"].astype("float") # Now it is converted into floating Value

#Now loading this into the Dataset
data["kms_driven"]=data["kms_driven"].astype("int") # Now it is converted into int Value

data.info()

data.head(5)

"""# 📌 Fuel_Type , Transmissoin , Ownership ---> this will be same as it is

# 📌Engine
"""

# i have to remove the cc
data["engine"]

## Removing the cc after space ---> removing that too
data['engine'] = data['engine'].str.replace(" cc", "")

# Now converitng to this as int value
data["engine"].astype("float") # Now it is converted into floating Value

#Now loading this into the Dataset
data["engine"]=data["engine"].astype("int") # Now it is converted into int Value

data.head(2)

"""# 📌Seats"""

data['Seats']

# Removing the seats after space ---> removing this too
data['Seats'] = data['Seats'].str.replace(" Seats", "")

# Now converitng to this as int value
data["Seats"].astype("float") # Now it is converted into floating Value

#Now loading this into the Dataset
data["Seats"]=data["Seats"].astype("int") # Now it is converted into int Value

data.info()

data.head(2)

"""# 📌Manufacture or Date --> 15/january/2017  or 15/1/2017"""

data["manufacture"]

# Pandas pre-defined Date format Funciton
pd.to_datetime(data['manufacture'])

data.info()

"""# ✅ Finally impriting the Cleaned Data"""

data.to_csv(r'C:\Users\hirak\Downloads\Data Cleaning For Data Analyst\Cleaned_Car_price_Data.csv')















